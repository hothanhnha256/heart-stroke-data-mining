# ğŸ¥ Heart Stroke Prediction - Data Mining Project

[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.4.2-orange.svg)](https://scikit-learn.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)

Dá»± Ã¡n **Data Mining hoÃ n chá»‰nh** Ä‘á»ƒ dá»± Ä‘oÃ¡n nguy cÆ¡ Ä‘á»™t quá»µ (stroke) dá»±a trÃªn dá»¯ liá»‡u y táº¿ vÃ  nhÃ¢n kháº©u há»c, sá»­ dá»¥ng Machine Learning.

---

## ï¿½ **Dataset Overview**

- **Nguá»“n**: Healthcare Dataset Stroke Data (Kaggle)
- **KÃ­ch thÆ°á»›c**: 5,110 bá»‡nh nhÃ¢n Ã— 12 thuá»™c tÃ­nh
- **Target**: Dá»± Ä‘oÃ¡n Ä‘á»™t quá»µ (stroke: 0/1)
- **Váº¥n Ä‘á»**: **Class Imbalance** nghiÃªm trá»ng (95.1% khÃ´ng Ä‘á»™t quá»µ, 4.9% Ä‘á»™t quá»µ)

---

## ï¿½ğŸ“ **Project Structure**

```
heart-stroke/
â”‚
â”œâ”€â”€ ğŸ“Š DATA
â”‚   â”œâ”€â”€ data-raw/
â”‚   â”‚   â””â”€â”€ healthcare-dataset-stroke-data.csv    # Dataset gá»‘c
â”‚   â”œâ”€â”€ data-pre/                                 # Dá»¯ liá»‡u Ä‘Ã£ preprocessing
â”‚   â”‚   â”œâ”€â”€ train_preprocessed.csv               # Training (7,778 rows sau SMOTE)
â”‚   â”‚   â”œâ”€â”€ test_preprocessed.csv                # Test (1,022 rows)
â”‚   â”‚   â”œâ”€â”€ preprocessor.joblib                  # Sklearn pipeline
â”‚   â”‚   â”œâ”€â”€ feature_names.txt                    # 21 features
â”‚   â”‚   â””â”€â”€ prep_meta.json                       # Metadata
â”‚   â”œâ”€â”€ eda/                                     # EDA visualizations
â”‚   â””â”€â”€ feature/                                 # Feature selection results
â”‚
â”œâ”€â”€ ğŸ”§ CORE SCRIPTS
â”‚   â”œâ”€â”€ prepare-stroke.py                        # Preprocessing pipeline â­
â”‚   â”œâ”€â”€ eda_analysis.py                          # Exploratory analysis
â”‚   â”œâ”€â”€ feature_selection.py                     # Multi-method selection
â”‚   â””â”€â”€ model_consolidation.py                   # Results aggregation
â”‚
â”œâ”€â”€ ğŸ¤– MODELS
â”‚   â”œâ”€â”€ implement.py                             # Baseline LogReg
â”‚   â”œâ”€â”€ model-A/                                 # Team member A
â”‚   â”‚   â”œâ”€â”€ logistics_reg.py
â”‚   â”‚   â””â”€â”€ random_forest.py
â”‚   â””â”€â”€ model-B/                                 # Team member B
â”‚       â”œâ”€â”€ svm.py
â”‚       â””â”€â”€ svm-and-knn.ipynb
â”‚
â”œâ”€â”€ ğŸ“– DOCUMENTATION
â”‚   â”œâ”€â”€ README.md                                # This file
â”‚   â”œâ”€â”€ REPORT.md                                # Detailed analysis report
â”‚   â”œâ”€â”€ REPORT_TEMPLATE.md                       # Report template
â”‚   â””â”€â”€ .github/copilot-instructions.md          # AI coding guidelines
â”‚
â””â”€â”€ âš™ï¸ CONFIG
    â”œâ”€â”€ requirements.txt                         # Python dependencies
    â””â”€â”€ .gitignore
```

````

---

## ğŸš€ **Quick Start**

### 1ï¸âƒ£ Environment Setup

**Windows (PowerShell):**

```powershell
# Clone repository
git clone https://github.com/hothanhnha256/heart-stroke-data-mining.git
cd heart-stroke-data-mining

# Create virtual environment
python -m venv .venv
.venv\Scripts\activate

# Upgrade pip and install dependencies
pip install -U pip
pip install -r requirements.txt
````

**Ubuntu/Linux:**

```bash
# Clone repository
git clone https://github.com/hothanhnha256/heart-stroke-data-mining.git
cd heart-stroke-data-mining

# Create virtual environment
python3 -m venv .venv
source .venv/bin/activate

# Upgrade pip and install dependencies
pip install -U pip
pip install -r requirements.txt
```

### 2ï¸âƒ£ Verify Installation

```powershell
# Check Python version (cáº§n >= 3.9)
python --version

# Check installed packages
pip list | Select-String "pandas|numpy|scikit-learn"
```

---

## ğŸ“‹ **Complete Workflow**

### **Step 1: Exploratory Data Analysis (EDA)**

PhÃ¢n tÃ­ch vÃ  hiá»ƒu dataset trÆ°á»›c khi xá»­ lÃ½:

```powershell
python eda_analysis.py
```

**Outputs:**

- âœ… Thá»‘ng kÃª mÃ´ táº£ dataset
- âœ… PhÃ¢n tÃ­ch class imbalance (4.9% stroke)
- âœ… Distributions cá»§a numeric features
- âœ… Correlation analysis
- âœ… Age group analysis
- âœ… Visualizations: `eda/*.png`

**Key Insights:**

- Class imbalance nghiÃªm trá»ng: 95.1% No Stroke, 4.9% Stroke
- Missing values: BMI cÃ³ 201 giÃ¡ trá»‹ thiáº¿u
- Outliers: `bmi` vÃ  `avg_glucose_level` cáº§n xá»­ lÃ½
- Age lÃ  yáº¿u tá»‘ quan trá»ng nháº¥t

---

### **Step 2: Data Preprocessing**

Tiá»n xá»­ lÃ½ dá»¯ liá»‡u vá»›i pipeline hoÃ n chá»‰nh:

```powershell
python prepare-stroke.py `
  --input data-raw/healthcare-dataset-stroke-data.csv `
  --output-dir data-pre `
  --scale standard `
  --cap-outliers `
  --smote
```

**Parameters:**

- `--input`: ÄÆ°á»ng dáº«n tá»›i CSV gá»‘c
- `--output-dir`: ThÆ° má»¥c lÆ°u artifacts (default: `data-pre/`)
- `--test-size`: Tá»· lá»‡ test set (default: 0.2)
- `--scale`: PhÆ°Æ¡ng phÃ¡p scaling `standard|minmax|none` (default: standard)
- `--cap-outliers`: Báº­t outlier capping báº±ng IQR method
- `--smote`: Báº­t SMOTE oversampling cho training set
- `--random-state`: Random seed (default: 42)

**Processing Steps:**

1. **NaN Handling**
   - Numeric: Median imputation
   - Categorical: Most frequent imputation
2. **Outlier Treatment**

   - IQR-based capping cho `bmi` vÃ  `avg_glucose_level`
   - Formula: `[Q1 - 1.5Ã—IQR, Q3 + 1.5Ã—IQR]`

3. **Feature Encoding**

   - Categorical â†’ OneHotEncoder (14 features)
   - Numeric â†’ StandardScaler (3 features)
   - Binary â†’ Passthrough (2 features)

4. **Train/Test Split**

   - Stratified split (80/20)
   - Preserves class distribution

5. **SMOTE Oversampling**
   - Applied only on training set
   - Balances classes to 50-50

**Outputs:**

```
data-pre/
â”œâ”€â”€ train_preprocessed.csv    # 7,778 rows (balanced)
â”œâ”€â”€ test_preprocessed.csv     # 1,022 rows (original dist)
â”œâ”€â”€ preprocessor.joblib       # Fitted sklearn pipeline
â”œâ”€â”€ feature_names.txt         # 21 feature names
â””â”€â”€ prep_meta.json           # Metadata & statistics
```

---

### **Step 3: Feature Selection**

TÃ¬m features quan trá»ng nháº¥t vá»›i 4 phÆ°Æ¡ng phÃ¡p:

```powershell
python feature_selection.py
```

**Methods:**

1. **Correlation Analysis** - Pearson correlation vá»›i target
2. **Mutual Information** - Information gain measurement
3. **Random Forest Importance** - Tree-based feature importance
4. **Statistical Tests** - ANOVA (numeric) + Chi-square (categorical)

**Combined Ranking:**

- Normalize táº¥t cáº£ scores vá» [0, 1]
- TÃ­nh trung bÃ¬nh cá»§a 4 phÆ°Æ¡ng phÃ¡p
- Rank theo combined score

**Top 8 Features:**

1. ğŸ¥‡ **age** - Tuá»•i (quan trá»ng nháº¥t!)
2. ğŸ¥ˆ **avg_glucose_level** - Má»©c glucose
3. ğŸ¥‰ **bmi** - Chá»‰ sá»‘ BMI
4. **hypertension** - TÄƒng huyáº¿t Ã¡p
5. **heart_disease** - Bá»‡nh tim
6. **ever_married_Yes** - ÄÃ£ káº¿t hÃ´n
7. **work*type*\*** - Loáº¡i cÃ´ng viá»‡c
8. **smoking*status*\*** - TÃ¬nh tráº¡ng hÃºt thuá»‘c

**Outputs:**

```
feature/
â”œâ”€â”€ feature_correlation_analysis.png
â”œâ”€â”€ feature_mutual_info_analysis.png
â”œâ”€â”€ feature_rf_importance_analysis.png
â”œâ”€â”€ feature_statistical_analysis.png
â”œâ”€â”€ feature_combined_ranking.png
â””â”€â”€ feature_selection_results.json
```

---

### **Step 4: Model Training**

#### **A. Baseline Model**

Quick baseline vá»›i Logistic Regression:

```powershell
python implement.py
```

**Model Configuration:**

- Algorithm: Logistic Regression
- Hyperparameters: `max_iter=500`, `class_weight='balanced'`
- Metrics: Precision, Recall, F1-Score, Accuracy

#### **B. Advanced Models**

**Model A (Logistic Regression & Random Forest):**

```powershell
cd model-A
python logistics_reg.py
python random_forest.py
```

**Model B (SVM & KNN):**

```powershell
cd model-B
python svm.py
# Hoáº·c cháº¡y notebook:
jupyter notebook svm-and-knn.ipynb
```

---

### **Step 5: Results Consolidation**

Tá»•ng há»£p vÃ  so sÃ¡nh káº¿t quáº£ tá»« táº¥t cáº£ models:

```powershell
python model_consolidation.py
```

**Features:**

- âœ… Tá»•ng há»£p metrics tá»« nhiá»u models
- âœ… So sÃ¡nh performance (Accuracy, F1, Precision, Recall)
- âœ… Visualizations (bar charts, heatmaps, scatter plots)
- âœ… Detailed report generation
- âœ… Export results to JSON

**Outputs:**

```
model_results_comparison.png
detailed_model_report.txt
model_results_consolidated.json
```

---

## ğŸ“Š **Dataset Schema**

### Columns Description

| Column              | Type    | Description               | Example Values                                           |
| ------------------- | ------- | ------------------------- | -------------------------------------------------------- |
| `id`                | int     | Patient ID (dropped)      | 9046, 51676                                              |
| `gender`            | object  | Gender                    | Male, Female, Other                                      |
| `age`               | float   | Age in years              | 67, 61, 80                                               |
| `hypertension`      | int     | Hypertension (0/1)        | 0, 1                                                     |
| `heart_disease`     | int     | Heart disease (0/1)       | 0, 1                                                     |
| `ever_married`      | object  | Marital status            | Yes, No                                                  |
| `work_type`         | object  | Type of work              | Private, Govt_job, Self-employed, Never_worked, children |
| `Residence_type`    | object  | Residence type            | Urban, Rural                                             |
| `avg_glucose_level` | float   | Average glucose level     | 228.69, 202.21                                           |
| `bmi`               | float   | Body Mass Index           | 36.6, 32.5                                               |
| `smoking_status`    | object  | Smoking status            | formerly smoked, never smoked, smokes, Unknown           |
| **`stroke`**        | **int** | **Target variable (0/1)** | **0, 1**                                                 |

### Column Categorization for Preprocessing

```python
# Schema configuration
target_col = "stroke"
drop_cols = ["id"]  # Excluded from training

# Feature types
numeric_cols = ["age", "avg_glucose_level", "bmi"]
binary_cols = ["hypertension", "heart_disease"]
categorical_cols = ["gender", "ever_married", "work_type",
                   "Residence_type", "smoking_status"]
```

### After Preprocessing (21 Features)

**Numeric (3):**

- age
- avg_glucose_level
- bmi

**OneHot Encoded (14):**

- gender_Female, gender_Male, gender_Other
- ever_married_No, ever_married_Yes
- work_type_Govt_job, work_type_Never_worked, work_type_Private, work_type_Self-employed, work_type_children
- Residence_type_Rural, Residence_type_Urban
- smoking_status_Unknown, smoking_status_formerly smoked, smoking_status_never smoked, smoking_status_smokes

**Binary (2):**

- hypertension
- heart_disease

**Target (1):**

- stroke

---

## ğŸ” **Key Technical Decisions**

### 1. Class Imbalance Handling

**Problem:** 95.1% No Stroke vs 4.9% Stroke

**Solutions:**

- âœ… **SMOTE** oversampling (chá»‰ trÃªn training set)
- âœ… **class_weight='balanced'** trong models
- âœ… **Stratified sampling** trong train/test split
- âœ… **Metrics focus**: F1-Score, Precision, Recall (khÃ´ng chá»‰ Accuracy)

### 2. Data Leakage Prevention

```python
# âœ… CORRECT: Fit on train only
preprocessor.fit(X_train)
X_train_transformed = preprocessor.transform(X_train)
X_test_transformed = preprocessor.transform(X_test)

# âŒ WRONG: Fit on all data
preprocessor.fit(X)  # Information leakage!
```

### 3. Pipeline Architecture

```
Raw Data
    â†“
Missing Value Imputation
    â†“
Outlier Capping (optional)
    â†“
Train/Test Split (stratified)
    â†“
Feature Encoding & Scaling
    â†“
SMOTE (training only)
    â†“
Model Training
```

---

## ğŸ“ˆ **Performance Metrics**

### Priority Metrics (for imbalanced data)

1. **F1-Score** â­â­â­ - Harmonic mean of Precision & Recall
2. **Precision** â­â­â­ - Tá»· lá»‡ dá»± Ä‘oÃ¡n Ä‘Ãºng trong cÃ¡c positive predictions
3. **Recall** â­â­â­ - Tá»· lá»‡ tÃ¬m Ä‘Æ°á»£c trong cÃ¡c positive cases
4. **ROC-AUC** â­â­ - Area under ROC curve
5. **Accuracy** â­ - Chá»‰ dÃ¹ng Ä‘á»ƒ tham kháº£o (misleading vá»›i imbalanced data)

### Why not Accuracy?

```
Example vá»›i dataset:
- 95% No Stroke, 5% Stroke
- Model dá»± Ä‘oÃ¡n Táº¤T Cáº¢ lÃ  "No Stroke"
- Accuracy = 95% (looks good!)
- NhÆ°ng: Recall = 0% (completely useless!)

â†’ F1-Score lÃ  metric tá»‘t hÆ¡n!
```

---

## ğŸ› ï¸ **Development Tools**

### Required Dependencies

```txt
# Core
numpy==1.26.4
pandas==2.2.2

# ML Framework
scikit-learn==1.4.2
scipy==1.11.4
joblib==1.3.2

# Imbalanced Learning
imbalanced-learn==0.12.3

# Visualization
matplotlib==3.8.4
seaborn==0.13.2
```

### Optional Tools

```powershell
# Jupyter for notebooks
pip install jupyter

# Code formatting
pip install black

# Linting
pip install pylint
```

---

## ğŸ“š **Documentation**

- **README.md** - Project overview vÃ  quick start (this file)
- **REPORT.md** - Detailed analysis report vá»›i findings
- **REPORT_TEMPLATE.md** - Template cho bÃ¡o cÃ¡o Ä‘áº§y Ä‘á»§
- **.github/copilot-instructions.md** - AI coding guidelines

---

## ğŸ¤ **Team Collaboration**

### Branch Strategy

```
main (hoáº·c master)
â”œâ”€â”€ model_A - Logistic Regression & Random Forest
â””â”€â”€ model_B - SVM & KNN
```

### Adding Your Model Results

```python
from model_consolidation import ModelResultsConsolidator

consolidator = ModelResultsConsolidator()

# Add your model
consolidator.add_model_result(
    model_name="Your Model Name",
    member_name="Your Name",
    y_true=y_test,
    y_pred=y_pred,
    model_params={"param1": value1},
    preprocessing_info={"scaler": "Standard", "smote": True}
)

# Generate reports
consolidator.print_summary()
consolidator.visualize_results()
consolidator.save_results_to_json()
```

---

## ğŸ¯ **Common Issues & Solutions**

### Issue 1: Import Error

```
ModuleNotFoundError: No module named 'sklearn'
```

**Solution:**

```powershell
# Activate venv first!
.venv\Scripts\activate
pip install -r requirements.txt
```

### Issue 2: SMOTE Not Found

```
RuntimeError: Báº¡n Ä‘Ã£ báº­t --smote nhÆ°ng chÆ°a cÃ i imbalanced-learn
```

**Solution:**

```powershell
pip install imbalanced-learn
```

### Issue 3: File Not Found

```
FileNotFoundError: data-raw/healthcare-dataset-stroke-data.csv
```

**Solution:**

- Äáº£m báº£o file CSV á»Ÿ Ä‘Ãºng thÆ° má»¥c `data-raw/`
- Check tÃªn file chÃ­nh xÃ¡c

### Issue 4: Memory Error (large dataset)

**Solution:**

```python
# Giáº£m SMOTE samples
sm = SMOTE(sampling_strategy=0.5)  # Instead of 1.0

# Hoáº·c dÃ¹ng batch processing
```

---

## ğŸ“ **To-Do List**

- [x] Dataset exploration & EDA
- [x] Preprocessing pipeline
- [x] Feature selection
- [x] Train/test split vá»›i stratification
- [x] SMOTE implementation
- [x] Baseline model (Logistic Regression)
- [ ] Advanced models (SVM, KNN, RF)
- [ ] Hyperparameter tuning
- [ ] Cross-validation
- [ ] Ensemble methods
- [ ] Final report writing

---

## ğŸ“– **References**

- [Kaggle Dataset](https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset)
- [SMOTE Paper](https://arxiv.org/abs/1106.1813)
- [Imbalanced Learning](https://imbalanced-learn.org/)
- [Scikit-learn Documentation](https://scikit-learn.org/)

---

## ğŸ‘¥ **Contributors**

- **Member A** - Logistic Regression & Random Forest
- **Member B** - SVM & KNN
- **Team** - EDA, Preprocessing, Feature Selection, Consolidation

---

## ğŸ™ **Acknowledgments**

- Dataset: Kaggle Healthcare Stroke Dataset
- Framework: Scikit-learn, Pandas, NumPy
- Inspiration: Data Mining coursework HK251

---

**Happy Coding! ğŸš€**
binary_cols = ["hypertension", "heart_disease"]
categorical_cols = ["gender", "ever_married", "work_type", "Residence_type", "smoking_status"]

````

---

## ğŸ” Key Insights

### Top Risk Factors (tá»« Feature Selection):

1. **Age** - Yáº¿u tá»‘ quan trá»ng nháº¥t
2. **Average Glucose Level** - Chá»‰ sá»‘ glucose
3. **BMI** - Chá»‰ sá»‘ khá»‘i cÆ¡ thá»ƒ
4. **Hypertension** - TÄƒng huyáº¿t Ã¡p
5. **Heart Disease** - Bá»‡nh tim

### EDA Findings:

- Nguy cÆ¡ stroke tÄƒng Ä‘Ã¡ng ká»ƒ sau 50 tuá»•i
- Class imbalance nghiÃªm trá»ng cáº§n SMOTE
- BMI vÃ  glucose levels cÃ³ outliers cáº§n xá»­ lÃ½

---

## ğŸ› ï¸ Advanced Usage

### Custom Preprocessing

```powershell
# KhÃ´ng SMOTE, sá»­ dá»¥ng MinMax scaling
python prepare-stroke.py --input data-raw/healthcare-dataset-stroke-data.csv --output-dir data-pre --scale minmax

# Test size 30%, khÃ´ng cap outliers
python prepare-stroke.py --input data-raw/healthcare-dataset-stroke-data.csv --output-dir data-pre --test-size 0.3
````

### Team Collaboration

```python
from model_consolidation import ModelResultsConsolidator

consolidator = ModelResultsConsolidator()
consolidator.add_model_result("Random Forest", "Member A", y_true, y_pred)
consolidator.print_summary()
consolidator.visualize_results()
```

---

## ğŸ“š Dependencies

**Core ML Stack:**

- pandas==2.2.2
- scikit-learn==1.4.2
- numpy==1.26.4

**Visualization & Analysis:**

- matplotlib==3.8.4
- seaborn==0.13.2

**Optional:**

- imbalanced-learn==0.12.3 (cho SMOTE)

---

## ğŸ“– Documentation

- **Detailed Report**: Xem `REPORT_TEMPLATE.md`
- **AI Guidelines**: `.github/copilot-instructions.md`
- **Code Structure**: Táº¥t cáº£ scripts cÃ³ docstrings Vietnamese

---

## ğŸ† Project Highlights

- âœ… **Reproducible Pipeline**: Seed-controlled, artifact-based
- âœ… **Class Imbalance Handling**: SMOTE + Stratified sampling
- âœ… **Multi-method Feature Selection**: 4 different approaches
- âœ… **Comprehensive EDA**: Statistical + Visual analysis
- âœ… **Team Collaboration**: Results consolidation framework
- âœ… **Production Ready**: Error handling, Vietnamese docs

---

**ğŸ“ Note**: ÄÃ¢y lÃ  pipeline hoÃ n chá»‰nh cho phÃ¢n tÃ­ch dá»¯ liá»‡u stroke prediction. Má»—i script cÃ³ thá»ƒ cháº¡y Ä‘á»™c láº­p hoáº·c theo workflow trÃªn.
