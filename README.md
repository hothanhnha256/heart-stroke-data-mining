# Heart Stroke Data Mining Project

Dá»± Ã¡n phÃ¢n tÃ­ch vÃ  dá»± Ä‘oÃ¡n nguy cÆ¡ Ä‘á»™t quá»µ sá»­ dá»¥ng Machine Learning.

## ğŸ“ Project Structure

```
heart-stroke/
â”œâ”€â”€ data-raw/
â”‚   â””â”€â”€ healthcare-dataset-stroke-data.csv    # Dataset gá»‘c (5,111 rows Ã— 12 cols)
â”œâ”€â”€ data-pre/                                 # Dá»¯ liá»‡u Ä‘Ã£ preprocessing
â”‚   â”œâ”€â”€ train_preprocessed.csv               # Training set Ä‘Ã£ xá»­ lÃ½
â”‚   â”œâ”€â”€ test_preprocessed.csv                # Test set Ä‘Ã£ xá»­ lÃ½
â”‚   â”œâ”€â”€ preprocessor.joblib                  # Sklearn pipeline
â”‚   â”œâ”€â”€ feature_names.txt                    # Danh sÃ¡ch features
â”‚   â””â”€â”€ prep_meta.json                       # Metadata
â”œâ”€â”€ eda/                                      # EDA visualizations
â”‚   â””â”€â”€ eda_*.png                            # Charts vÃ  plots
â”œâ”€â”€ feature/                                  # Feature selection results
â”‚   â”œâ”€â”€ feature_*.png                        # Feature importance plots
â”‚   â””â”€â”€ feature_selection_results.json       # Ranking results
â”œâ”€â”€ model-A/                                  # Models - Team A
â”‚   â”œâ”€â”€ logistics_reg.py                     # Logistic Regression
â”‚   â””â”€â”€ random_forest.py                     # Random Forest
â”œâ”€â”€ model-B/                                  # Models - Team B
â”‚   â”œâ”€â”€ svm.py                               # Support Vector Machine
â”‚   â””â”€â”€ svm-and-knn.ipynb                    # SVM + KNN notebook
â”œâ”€â”€ report/                                   # LaTeX academic report
â”‚   â”œâ”€â”€ main.tex                             # Main document
â”‚   â”œâ”€â”€ Section 2/ ... Section 8/            # Report chapters
â”‚   â””â”€â”€ image/                               # Report images
â”œâ”€â”€ prepare-stroke.py                        # Main preprocessing pipeline
â”œâ”€â”€ implement.py                             # Simple model implementation
â”œâ”€â”€ eda_analysis.py                          # Exploratory Data Analysis
â”œâ”€â”€ feature_selection.py                     # Multi-method feature selection
â”œâ”€â”€ model_consolidation.py                   # Tá»•ng há»£p káº¿t quáº£ tá»« team
â”œâ”€â”€ README.md                                # Documentation (this file)
â””â”€â”€ requirements.txt                         # Dependencies
```

## ğŸš€ Quick Start

### Environment Setup

**Windows:**

```powershell
python -m venv .venv
.venv\Scripts\activate
pip install -U pip
pip install -r requirements.txt
```

**Ubuntu:**

```bash
python -m venv .venv
source .venv/bin/activate
pip install -U pip
pip install -r requirements.txt
```

### Main Workflow

## ğŸ“Š Step 1: Exploratory Data Analysis

```powershell
python eda_analysis.py
```

**Outputs:**

- Thá»‘ng kÃª mÃ´ táº£ dataset
- PhÃ¢n tÃ­ch target distribution (class imbalance: 4.9% stroke)
- Visualizations: distributions, correlations, age analysis
- Files: `eda_*.png`

## ğŸ”§ Step 2: Data Preprocessing

```powershell
python prepare-stroke.py --input data-raw/healthcare-dataset-stroke-data.csv --output-dir data-pre --scale standard --cap-outliers --smote
```

**Key Features:**

- **NaN handling**: Median imputer cho numeric, most_frequent cho categorical
- **Outlier capping**: IQR-based cho `bmi` vÃ  `avg_glucose_level`
- **Encoding**: OneHotEncoder vá»›i `handle_unknown='ignore'`
- **Scaling**: StandardScaler/MinMaxScaler options
- **Train/Test Split**: Stratified split (80/20)
- **Class Balancing**: SMOTE oversampling (optional)

**Parameters:**

- `--input`: Path Ä‘áº¿n CSV gá»‘c
- `--output-dir`: ThÆ° má»¥c lÆ°u artifacts
- `--test-size`: Tá»· lá»‡ test set (default: 0.2)
- `--scale`: `standard|minmax|none` (default: standard)
- `--cap-outliers`: Báº­t outlier capping
- `--smote`: Báº­t SMOTE oversampling
- `--random-state`: Random seed (default: 42)

## ğŸ¯ Step 3: Feature Selection

```powershell
python feature_selection.py
```

**Methods:**

1. **Correlation Analysis**: Pearson correlation vá»›i target
2. **Mutual Information**: Information gain
3. **Random Forest Importance**: Tree-based importance
4. **Statistical Tests**: ANOVA (numeric) + Chi-square (categorical)

**Outputs:**

- Combined ranking cá»§a táº¥t cáº£ features
- Top K features quan trá»ng nháº¥t
- Visualizations: `feature_*.png`
- Results: `feature_selection_results.json`

## ğŸ¤– Step 4: Model Training

```powershell
python implement.py
```

Simple LogisticRegression baseline model.

## ğŸ“‹ Step 5: Results Consolidation

```powershell
python model_consolidation.py
```

Framework Ä‘á»ƒ tá»•ng há»£p káº¿t quáº£ tá»« cÃ¡c thÃ nh viÃªn trong team.

---

## ğŸ“„ Step 6: Generate Academic Report (LaTeX)

### Report Structure

```
report/
â”œâ”€â”€ main.tex                    # Main LaTeX document
â”œâ”€â”€ division_of_work.tex        # PhÃ¢n cÃ´ng cÃ´ng viá»‡c
â”œâ”€â”€ resources.tex               # TÃ i liá»‡u tham kháº£o
â”œâ”€â”€ Section 2/
â”‚   â””â”€â”€ index.tex              # Giá»›i thiá»‡u
â”œâ”€â”€ Section 3/
â”‚   â””â”€â”€ index.tex              # CÆ¡ sá»Ÿ lÃ½ thuyáº¿t
â”œâ”€â”€ Section 4/
â”‚   â””â”€â”€ index.tex              # Kháº£o sÃ¡t vÃ  phÃ¢n tÃ­ch dá»¯ liá»‡u (EDA)
â”œâ”€â”€ Section 5/
â”‚   â””â”€â”€ index.tex              # Tiá»n xá»­ lÃ½ dá»¯ liá»‡u
â”œâ”€â”€ Section 6/
â”‚   â””â”€â”€ index.tex              # XÃ¢y dá»±ng mÃ´ hÃ¬nh
â”œâ”€â”€ Section 7/
â”‚   â””â”€â”€ index.tex              # Káº¿t quáº£ vÃ  Ä‘Ã¡nh giÃ¡
â””â”€â”€ Section 8/
    â””â”€â”€ index.tex              # Káº¿t luáº­n
```

### Compile LaTeX Report

**Windows (PowerShell):**

```powershell
cd report
pdflatex -interaction=nonstopmode main.tex
pdflatex -interaction=nonstopmode main.tex  # Cháº¡y 2 láº§n Ä‘á»ƒ cáº­p nháº­t TOC
```

**Ubuntu/Linux:**

```bash
cd report
pdflatex -interaction=nonstopmode main.tex
pdflatex -interaction=nonstopmode main.tex  # Cháº¡y 2 láº§n Ä‘á»ƒ cáº­p nháº­t TOC
```

**Notes:**

- Flag `-interaction=nonstopmode`: Tá»± Ä‘á»™ng bá» qua errors vÃ  tiáº¿p tá»¥c compile
- Cháº¡y 2 láº§n Ä‘á»ƒ cáº­p nháº­t Table of Contents vÃ  cross-references
- Output: `main.pdf` trong thÆ° má»¥c `report/`
- Cáº§n cÃ i Ä‘áº·t MiKTeX (Windows) hoáº·c TeX Live (Linux/Mac)

### Report Content

- **Section 2**: Giá»›i thiá»‡u vá» bÃ i toÃ¡n dá»± Ä‘oÃ¡n Ä‘á»™t quá»µ
- **Section 3**: CÆ¡ sá»Ÿ lÃ½ thuyáº¿t (Binary Classification, Metrics, SMOTE, Algorithms: LogReg, RF, SVM, KNN)
- **Section 4**: EDA vá»›i Professional Theme visualizations
- **Section 5**: Tiá»n xá»­ lÃ½ dá»¯ liá»‡u (Missing values, Outliers, Scaling, SMOTE)
- **Section 6**: XÃ¢y dá»±ng 4 mÃ´ hÃ¬nh ML
- **Section 7**: So sÃ¡nh káº¿t quáº£ vÃ  Ä‘Ã¡nh giÃ¡
- **Section 8**: Káº¿t luáº­n vÃ  hÆ°á»›ng phÃ¡t triá»ƒn

### Troubleshooting LaTeX Compile

**Compile timeout:**

- Kiá»ƒm tra file paths trong `\input{}` commands
- Äáº£m báº£o táº¥t cáº£ images tá»“n táº¡i trong `report/image/`
- Táº¯t draft mode náº¿u Ä‘ang báº­t

**Missing packages:**

```powershell
# MiKTeX sáº½ tá»± Ä‘á»™ng cÃ i Ä‘áº·t packages thiáº¿u
# Hoáº·c cÃ i thá»§ cÃ´ng qua MiKTeX Console
```

**Permission errors:**

```powershell
# Äáº£m báº£o khÃ´ng má»Ÿ PDF Ä‘ang compile
# XÃ³a cÃ¡c file táº¡m: *.aux, *.log, *.toc
cd report
Remove-Item *.aux, *.log, *.toc, *.out
```

---

## ğŸ“Š Dataset Information

- **Source**: Healthcare Dataset Stroke Data (Kaggle)
- **Size**: 5,111 rows Ã— 12 columns
- **Target**: `stroke` (binary: 0/1)
- **Class Imbalance**: 95.1% No Stroke, 4.9% Stroke
- **Missing Values**: `bmi` column cÃ³ N/A values

### Schema

```python
target_col = "stroke"
drop_cols = ["id"]  # KhÃ´ng dÃ¹ng Ä‘á»ƒ train
numeric_cols = ["age", "avg_glucose_level", "bmi"]
binary_cols = ["hypertension", "heart_disease"]
categorical_cols = ["gender", "ever_married", "work_type", "Residence_type", "smoking_status"]
```

---

## ğŸ” Key Insights

### Top Risk Factors (tá»« Feature Selection):

1. **Age** - Yáº¿u tá»‘ quan trá»ng nháº¥t
2. **Average Glucose Level** - Chá»‰ sá»‘ glucose
3. **BMI** - Chá»‰ sá»‘ khá»‘i cÆ¡ thá»ƒ
4. **Hypertension** - TÄƒng huyáº¿t Ã¡p
5. **Heart Disease** - Bá»‡nh tim

### EDA Findings:

- Nguy cÆ¡ stroke tÄƒng Ä‘Ã¡ng ká»ƒ sau 50 tuá»•i
- Class imbalance nghiÃªm trá»ng cáº§n SMOTE
- BMI vÃ  glucose levels cÃ³ outliers cáº§n xá»­ lÃ½

---

## ğŸ› ï¸ Advanced Usage

### Custom Preprocessing

```powershell
# KhÃ´ng SMOTE, sá»­ dá»¥ng MinMax scaling
python prepare-stroke.py --input data-raw/healthcare-dataset-stroke-data.csv --output-dir data-pre --scale minmax

# Test size 30%, khÃ´ng cap outliers
python prepare-stroke.py --input data-raw/healthcare-dataset-stroke-data.csv --output-dir data-pre --test-size 0.3
```

### Team Collaboration

```python
from model_consolidation import ModelResultsConsolidator

consolidator = ModelResultsConsolidator()
consolidator.add_model_result("Random Forest", "Member A", y_true, y_pred)
consolidator.print_summary()
consolidator.visualize_results()
```

---

## ğŸ“š Dependencies

**Core ML Stack:**

- pandas==2.2.2
- scikit-learn==1.4.2
- numpy==1.26.4

**Visualization & Analysis:**

- matplotlib==3.8.4
- seaborn==0.13.2

**Optional:**

- imbalanced-learn==0.12.3 (cho SMOTE)

---

## ğŸ“– Documentation

- **Detailed Report**: Xem `REPORT_TEMPLATE.md`
- **AI Guidelines**: `.github/copilot-instructions.md`
- **Code Structure**: Táº¥t cáº£ scripts cÃ³ docstrings Vietnamese

---

## ğŸ† Project Highlights

- âœ… **Reproducible Pipeline**: Seed-controlled, artifact-based
- âœ… **Class Imbalance Handling**: SMOTE + Stratified sampling
- âœ… **Multi-method Feature Selection**: 4 different approaches
- âœ… **Comprehensive EDA**: Statistical + Visual analysis
- âœ… **Team Collaboration**: Results consolidation framework
- âœ… **Production Ready**: Error handling, Vietnamese docs

---

**ğŸ“ Note**: ÄÃ¢y lÃ  pipeline hoÃ n chá»‰nh cho phÃ¢n tÃ­ch dá»¯ liá»‡u stroke prediction. Má»—i script cÃ³ thá»ƒ cháº¡y Ä‘á»™c láº­p hoáº·c theo workflow trÃªn.
